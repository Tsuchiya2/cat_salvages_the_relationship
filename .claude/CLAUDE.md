---
description: EDAF v1.0 Configuration and Language Preferences
---

# EDAF v1.0 - Claude Code Configuration

## Language Preferences

This file is auto-generated by `/setup` command.
Do not edit manually - run `/setup` again to change preferences.

**Current Settings:**

- **Documentation Language**: English
- **Terminal Output Language**: Japanese
- **Save Dual Language Docs**: No

---

## EDAF 4-Phase Gate System - IMPORTANT

**When the user requests to implement a feature using "„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éï„É≠„Éº" (agent flow) or "EDAF", you MUST follow this exact workflow:**

### Phase 1: Design Gate
1. Launch `designer` agent via Task tool
2. Designer creates design document in `docs/designs/{feature-slug}.md`
3. Launch ALL 7 design evaluators in parallel via Task tool:
   - design-consistency-evaluator
   - design-extensibility-evaluator
   - design-goal-alignment-evaluator
   - design-maintainability-evaluator
   - design-observability-evaluator
   - design-reliability-evaluator
   - design-reusability-evaluator
4. Review evaluation results
5. If evaluators request changes, ask designer to revise
6. Repeat until all evaluators approve (‚â• 7.0/10.0)

### Phase 2: Planning Gate
1. Launch `planner` agent via Task tool
2. Planner creates task plan in `docs/plans/{feature-slug}-tasks.md`
3. Launch ALL 7 planner evaluators in parallel via Task tool:
   - planner-clarity-evaluator
   - planner-deliverable-structure-evaluator
   - planner-dependency-evaluator
   - planner-goal-alignment-evaluator
   - planner-granularity-evaluator
   - planner-responsibility-alignment-evaluator
   - planner-reusability-evaluator
4. Review evaluation results
5. If evaluators request changes, ask planner to revise
6. Repeat until all evaluators approve (‚â• 7.0/10.0)

### Phase 2.5: Implementation
1. Launch appropriate worker agents via Task tool based on task plan:
   - database-worker-v1-self-adapting (for database models)
   - backend-worker-v1-self-adapting (for backend logic)
   - frontend-worker-v1-self-adapting (for UI components)
   - test-worker-v1-self-adapting (for tests)
2. Workers implement code according to task plan

### Phase 3: Code Review Gate
1. Launch ALL 7 code evaluators in parallel via Task tool:
   - code-quality-evaluator-v1-self-adapting
   - code-testing-evaluator-v1-self-adapting
   - code-security-evaluator-v1-self-adapting
   - code-documentation-evaluator-v1-self-adapting
   - code-maintainability-evaluator-v1-self-adapting
   - code-performance-evaluator-v1-self-adapting
   - code-implementation-alignment-evaluator-v1-self-adapting
2. Review evaluation results
3. **If frontend files were modified (views, components, CSS, JavaScript):**
   - **MANDATORY: Always ask user for login information:**
     - Use AskUserQuestion tool: "Do the modified pages require login to view?"
     - If YES, collect:
       - Login URL (e.g., http://localhost:3000/login)
       - Email/Username
       - Password
     - Confirm development server is running
     - If NO, proceed without login
   - **MANDATORY: Create screenshot directory:**
     - Create directory: `docs/screenshots/{feature-name}/`
     - Example: `docs/screenshots/user-authentication/`
     - All screenshots will be saved in this directory
   - **MANDATORY: Use MCP chrome-devtools for UI/UX verification:**
     - Prerequisites verification:
       - Confirm development server is running (from user response above)
       - Identify all URLs to verify from design document
     - **Step 1: Setup and Authentication (if needed)**
       - `mcp__chrome-devtools__list_pages` - List available browser tabs
       - `mcp__chrome-devtools__navigate_page` - Navigate to login page (if required)
       - `mcp__chrome-devtools__fill` - Fill login credentials (if required)
       - `mcp__chrome-devtools__click` - Click login button (if required)
       - Verify successful login
     - **Step 2: Page-by-Page Verification (MANDATORY - DO NOT SKIP)**
       - For EACH modified page or component:
         1. `mcp__chrome-devtools__navigate_page` - Navigate to the page
         2. **`mcp__chrome-devtools__take_snapshot` - MANDATORY: Capture screenshot**
            - Save to: `docs/screenshots/{feature-name}/{page-name}.png`
            - Example: `docs/screenshots/user-authentication/login-page.png`
         3. Compare screenshot with design document specifications
         4. Check for visual inconsistencies (layout, colors, fonts, spacing)
         5. Document findings with screenshot reference (use relative path)
     - **Step 3: Interactive Element Testing**
       - For forms: `mcp__chrome-devtools__fill` - Test with sample data
       - For buttons/links: `mcp__chrome-devtools__click` - Test interactions
       - **`mcp__chrome-devtools__take_snapshot` - MANDATORY: Capture after each interaction**
         - Save to: `docs/screenshots/{feature-name}/{page-name}-{action}.png`
         - Example: `docs/screenshots/user-authentication/login-page-submitted.png`
       - Verify expected behaviors (validation, submission, navigation)
     - **Step 4: Console and Performance Check**
       - Check browser console for errors/warnings
       - Note any performance issues
     - **Step 5: Documentation (MANDATORY)**
       - Create review section with ALL screenshots included
       - Use relative paths: `![Screenshot](../screenshots/{feature-name}/{page-name}.png)`
       - List findings for each page/component
       - Compare actual vs expected behavior
       - **CRITICAL: Review MUST include at least one screenshot per modified page**
       - **Directory structure example:**
         ```
         docs/
         ‚îú‚îÄ‚îÄ reviews/{feature-name}-review.md
         ‚îî‚îÄ‚îÄ screenshots/{feature-name}/
             ‚îú‚îÄ‚îÄ login-page.png
             ‚îú‚îÄ‚îÄ login-page-submitted.png
             ‚îú‚îÄ‚îÄ dashboard.png
             ‚îî‚îÄ‚îÄ profile-page.png
         ```
4. If evaluators find issues OR UI verification fails, fix them
5. Repeat until all evaluators approve (‚â• 7.0/10.0) AND UI verification passes

### Phase 4: Deployment Gate (Optional)
1. Launch ALL 5 deployment evaluators in parallel via Task tool:
   - deployment-readiness-evaluator
   - production-security-evaluator
   - observability-evaluator
   - performance-benchmark-evaluator
   - rollback-plan-evaluator
2. Review evaluation results
3. If evaluators find issues, fix them
4. Repeat until all evaluators approve (‚â• 7.0/10.0)

**CRITICAL RULES:**
- NEVER skip phases
- NEVER launch evaluators directly - always use Task tool with subagent_type
- ALWAYS launch all evaluators in each phase in parallel
- ALWAYS wait for ALL evaluators to approve before proceeding to next phase

**NOTE:** Notification sounds will play automatically when each Task completes (configured via `.claude/settings.json` hooks)

---

## Instructions for Claude Code

When working with EDAF Workers and Evaluators, please follow these rules:

### 1. Terminal Output Language

**Respond to the user in JAPANESE for all terminal output, messages, and explanations.**

Examples:
- "‚úÖ „Éá„Éº„Çø„Éô„Éº„Çπ„É¢„Éá„É´„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü"
- "üìã „Ç≥„Éº„ÉâÂìÅË≥™Ë©ï‰æ°„ÇíÈñãÂßã„Åó„Åæ„Åô"
- "‚ùå „Ç®„É©„Éº: „Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"

### 2. Documentation Language

**Generate ALL documentation in ENGLISH.**

When creating markdown files, API documentation, README files, or code comments:
- Write in English
- Use standard English technical terms
- Provide English examples

Example:
```markdown
# User Model

## Overview

This model manages user information.

## Fields

- `email`: Email address (required)
- `password`: Password (hashed)
```

---

## Notification System

EDAF includes a sound notification system to alert you when tasks complete or errors occur.

### Automatic Notifications (via Hooks)

**Notifications play automatically** when any Task completes, thanks to Claude Code hooks configured in `.claude/settings.json`:

```json
{
  "hooks": {
    "tool-result": {
      "Task": "bash .claude/scripts/notification.sh 'Task completed' WarblerSong"
    }
  }
}
```

**What happens automatically:**
- When Designer completes ‚Üí WarblerSong plays (3 times, 1.8s intervals)
- When Planner completes ‚Üí WarblerSong plays
- When any Worker completes ‚Üí WarblerSong plays
- When any Evaluator completes ‚Üí WarblerSong plays

**No manual action required!** The notification system is fully automated.

### Manual Notifications (Optional)

You can also play notifications manually if needed:

```bash
bash .claude/scripts/notification.sh "Custom message" WarblerSong
```

**Available Sounds:**
- `WarblerSong` - Pleasant bird song (for task completion)
- `CatMeow` - Cat meow (for errors or attention needed)
- `Glass` - System glass sound (macOS only)

**Configuration:**
- Hook settings: `.claude/settings.json`
- Sound files: `.claude/sounds/`
- Notification script: `.claude/scripts/notification.sh`
- Playback: 3 times with 1.8 second intervals

---

## Worker-Specific Instructions

### Database Worker

When generating database models:
- Follow the documentation language setting above
- Use appropriate naming conventions for the target language
- Generate migration files with proper comments

### Backend Worker

When generating backend code:
- Follow the documentation language setting above
- Generate API documentation in the specified language
- Use proper error messages in the terminal output language

### Frontend Worker

When generating frontend components:
- Follow the documentation language setting above
- Generate component documentation in the specified language
- Use proper UI text in the terminal output language

### Test Worker

When generating tests:
- Follow the documentation language setting above
- Write test descriptions in the specified language
- Use proper assertion messages in the terminal output language

---

## Evaluator-Specific Instructions

All evaluators should:
- Output evaluation results in the terminal output language
- Generate reports in the documentation language
- Use proper scoring explanations in the terminal output language

---

## Project-Specific Information

### Technology Stack

**Backend:**
- Framework: Ruby on Rails 6.1.4
- Ruby Version: 3.0.2
- Database: MySQL2 (dev/test), PostgreSQL (production)
- ORM: ActiveRecord
- Authentication: Sorcery
- Authorization: Pundit
- Template Engine: Slim
- Testing: RSpec
- Code Quality: RuboCop (rails, performance, rspec)

**Frontend:**
- Module Bundler: Webpacker 5.0 (Webpack 4.46.0)
- CSS Framework: Bootstrap 5.1.3
- Icons: FontAwesome 5.15.4
- Rails Libraries: UJS, ActionCable, ActiveStorage

**Environment:**
- Execution: Local (no Docker)

---

**Last Updated**: Auto-generated by `/setup` command
**Configuration File**: `.claude/edaf-config.yml`
